<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Buevara</title>
  <icon>https://www.gravatar.com/avatar/b052651cafe03624e87490e24b7f70c4</icon>
  <subtitle>To hard!To work!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://Buevara.github.io/"/>
  <updated>2018-04-05T15:39:23.833Z</updated>
  <id>http://Buevara.github.io/</id>
  
  <author>
    <name>Buevara</name>
    <email>brian7law@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>瓜子二手车--数据分析岗位面经</title>
    <link href="http://Buevara.github.io/2018/04/05/%E7%93%9C%E5%AD%90%E4%BA%8C%E6%89%8B%E8%BD%A6--%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%B2%97%E4%BD%8D%E9%9D%A2%E7%BB%8F/"/>
    <id>http://Buevara.github.io/2018/04/05/瓜子二手车--数据挖掘算法岗位面经/</id>
    <published>2018-04-05T07:42:40.610Z</published>
    <updated>2018-04-05T15:39:23.833Z</updated>
    
    <content type="html"><![CDATA[<hr><p>面试约的上午九点半，去了直接面试，估计去的太早了。</p><hr><h3>一面</h3><ul><li><p>1.自我介绍.</p></li><li><p>2.介绍一下机器学习模型都有哪些，判别模型和生成模型区别，具体有哪些。</p></li><li><p>3.推导logistic的损失函数。</p></li><li><p>4.什么是过拟合，过拟合如何解决。</p></li><li><p>5.什么是gbdt，gbdt如何确定第一棵树，没答出来，她换了个问法，说给你两个特征x，x1是连续的，x2是非连续的，和对应的label，具体的构建gbdt的方法。</p></li><li><p>6.描述kmeans算法，难度加深，给定一个每个点和其他点的距离而不是坐标，该如何聚类。</p></li><li><p>7.最后一道算法题：不用内置函数求sqrt，给定x和 $\Sigma$, 其中$\Sigma$是误差项。应该用二分查找，但是最后没写出来。</p></li></ul><p>一面结束，三十分钟左右。</p><hr><h3>二面</h3><ul><li><p>1.自我介绍。</p></li><li><p>2.什么是极大似然估计，如何推导。</p></li><li><p>3.什么是最大后验概率，如何推导。</p></li><li><p>4.描述一下朴素贝叶斯。</p></li><li><p>5.算法题：旋转数组中找到x。leetcode33题</p></li><li><p>6.1求概率：得分问题，赢一局得一分，输一局，不扣分，赢和输概率为p和q，n局得到m分的概率是。</p></li><li><p>6.2前面的问题难度加大，输一局扣一分，求n局得到m分的概率是。</p></li><li><p>6.3难度再提升，扣为0分不降分，n局得到m分的概率是。当时没做出来（应该用动态规划）</p></li><li><p>7.1用一枚硬币（1/2的概率）求出一个1/3的概率。</p></li><li><p>7.2用一枚硬币（1/2的概率）求出一个1/3的概率。</p></li><li><p>7.3用不均匀一枚硬币（概率不为1/2）求出一个1/3的概率。</p></li></ul><p>二面面试官问我有什么要问的，我问了一下他所在的部门是做什么的，都有什么方向，他说在做分类推荐。二面结束，共四十分钟左右，面试官很和善，但是他出的问题都不是我自己独立解答的，80%都需要他的一些指引，认识到了自己的不足，继续努力。</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;面试约的上午九点半，去了直接面试，估计去的太早了。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;一面&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.自我介绍.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.介绍一下机器学习模型都有哪些，判别模型和生成模型区别，具体有哪些。&lt;/p&gt;
&lt;/li&gt;

      
    
    </summary>
    
    
      <category term="面经" scheme="http://Buevara.github.io/Tags/%E9%9D%A2%E7%BB%8F/"/>
    
      <category term="瓜子" scheme="http://Buevara.github.io/Tags/%E7%93%9C%E5%AD%90/"/>
    
      <category term="数据分析" scheme="http://Buevara.github.io/Tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>小米--机器学习岗位面经</title>
    <link href="http://Buevara.github.io/2018/03/31/%E5%B0%8F%E7%B1%B3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B2%97%E4%BD%8D%E9%9D%A2%E7%BB%8F/"/>
    <id>http://Buevara.github.io/2018/03/31/小米机器学习岗位面经/</id>
    <published>2018-03-31T11:40:13.000Z</published>
    <updated>2018-04-05T15:39:35.640Z</updated>
    
    <content type="html"><![CDATA[<hr><p>感谢两位校友@Marcovaldo和@KillersDeath提供的面经。面试约的下午三点，第一次面试，心里有点紧张。</p><hr><h3>一面</h3><ul><li><p>1.自我介绍.</p></li><li><p>2.介绍一下机器学习模型都有哪些。</p></li><li><p>3.深度学习网络的网络特性和不同，主要说了Alexnet和ResNet的主要特征。说的时候问到是不是用layers直接写，我说最早也用conv和pooling，relu写过浅层的网络。</p></li><li><p>4.梯度爆炸和梯度消失，梯度爆炸当时没理解清，没回答的很明白。这个解释很好：<a href="https://www.zhihu.com/question/66027838/" target="_blank" rel="noopener">梯度爆炸</a></p></li><li><p>5.项目上对如何找特征，用了什么模型和技巧，损失函数用的什么。我说用的gbdt，xgboost和SVM，他问我gbdt和SVM哪个对特征不需要处理（gbdt）， xgboost和gbdt的区别，回答速度快。问为什么xgboost速度快，回答用了二阶导数，问xgboost可以自定义损失函数，那你比赛利用的损失函数是什么，你对你的损失函数求一下二阶导，这坑挖的，算了半天没算出来。</p></li><li><p>6.L1、L2正则化的区别，为什么会产生稀疏性，为什么会降低特征权重。</p></li><li><p>7.给1张5*5*3的图片，3*3*64的卷积，用到了多少参数。（应该是想问我卷积层参数共享）</p></li><li><p>8.最后一道算法题：排序数组中给定某个重复出现数字第一次出现的下标。 剑指offer原题，算了半天用了两次二分查找，才写出来，面试官估计不咋满意。</p></li></ul><p>一面结束，四十分钟左右。</p><hr><h3>二面</h3><p>面试官应该是C++大神，想问我指针和数据流方面的题，但我都不会。于是问了三道算法题和一些小问题：</p><ul><li><p>1.一个n*m的矩阵，所有数无顺序，求第k大的数。想用快排，面试官说可以，但是不是最好的。最后没想出来，结束后和同学讨论应该是堆排序加上mapreduce。</p></li><li><p>2.反转链表。剑指offer原题。</p></li><li><p>3.中间问了一下函数的传参问题。</p></li><li><p>4.问了堆排序。</p></li><li><p>5.旋转数组找k。leetcode33题。</p></li></ul><p>二面结束，三十分钟左右，写算法特别慢，估计挂了。</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;感谢两位校友@Marcovaldo和@KillersDeath提供的面经。
面试约的下午三点，第一次面试，心里有点紧张。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;一面&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.自我介绍.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.介绍一下机器学习模
      
    
    </summary>
    
    
      <category term="小米" scheme="http://Buevara.github.io/Tags/%E5%B0%8F%E7%B1%B3/"/>
    
      <category term="机器学习" scheme="http://Buevara.github.io/Tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="面经" scheme="http://Buevara.github.io/Tags/%E9%9D%A2%E7%BB%8F/"/>
    
  </entry>
  
  <entry>
    <title>各种排序算法的性质</title>
    <link href="http://Buevara.github.io/2018/01/31/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    <id>http://Buevara.github.io/2018/01/31/排序算法/</id>
    <published>2018-01-31T02:12:56.000Z</published>
    <updated>2018-04-05T12:49:52.139Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>算法种类</th><th>最好情况</th><th>平均情况</th><th>最坏情况</th><th>空间复杂度</th><th>是否稳定</th></tr></thead><tbody><tr><td>直接插入排序</td><td>O(n)</td><td>O(n^2)</td><td>O(n^2)</td><td>O(1)</td><td>是</td></tr><tr><td>冒泡排序</td><td>O(n)</td><td>O(n^2)</td><td>O(n^2)</td><td>O(1)</td><td>是</td></tr><tr><td>简单选择排序</td><td>O(n^2)</td><td>O(n^2)</td><td>O(n^2)</td><td>O(1)</td><td>否</td></tr><tr><td>希尔排序</td><td></td><td></td><td></td><td>O(1)</td><td>否</td></tr><tr><td>快速排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(n^2)</td><td>O(logn)</td><td>否</td></tr><tr><td>堆排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(1)</td><td>否</td></tr><tr><td>2-路归并</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(n)</td><td>是</td></tr><tr><td>基数排序</td><td>O(d(n+r))</td><td>O(d(n+r))</td><td>O(d(n+r))</td><td>O(r)</td><td>是</td></tr></tbody></table><h2>快速排序</h2><p>快速排序是每趟都确定一个元素的位置，并且在它的位置左边的都比它小，在它右边的都比它大。</p><p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">void QuickSort(ElemType A[], int low, int high)&#123;</span><br><span class="line">    <span class="keyword">if</span>(low &lt; high)&#123;</span><br><span class="line">        int pivotpos = Partition(A, low, high);</span><br><span class="line">        QuickSort(A, low, pivotpos<span class="number">-1</span>);</span><br><span class="line">        QuickSort(A, pivotpos+<span class="number">1</span>, high);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int Partition(ElemType A[], int low, int high)&#123;</span><br><span class="line">    ElemType pivot = A[low];</span><br><span class="line">    <span class="keyword">while</span>(low &lt; high)&#123;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;high &amp;&amp; A[high] &gt; pivot) high--;</span><br><span class="line">        A[low] = A[high];</span><br><span class="line">        <span class="keyword">while</span>(low&lt;high &amp;&amp; A[low] &lt; pivot) low++;</span><br><span class="line">    &#125;</span><br><span class="line">    A[low] = pivot;</span><br><span class="line">    <span class="keyword">return</span> low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2>堆排序</h2><p>堆排序是先要构建成大顶堆，而后依次将root跟二叉树最后一个元素互换，每次互换后都要将二叉树再调整回大顶堆。</p><p>下面是建立大顶堆的过程：<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BuildMaxHeap</span><span class="params">(ElemType A[], <span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(i=len/<span class="number">2</span>;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">        AdjustDown(A, i, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">AdjustDown</span><span class="params">(ElemType A[], <span class="keyword">int</span> k, <span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    A[<span class="number">0</span>] = A[k];</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">2</span>*k;i&lt;=len;i*=<span class="number">2</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;len&amp;&amp;A[i]&lt;A[i+<span class="number">1</span>])</span><br><span class="line">            i++;</span><br><span class="line">        <span class="keyword">if</span>(A[i] &gt; A[<span class="number">0</span>])</span><br><span class="line">            A[k] = A[i];</span><br><span class="line">            k = i;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>下面是堆排序算法：<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">HeapSort</span><span class="params">(ElemType A[], <span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    BuildMaxHeap(A, len);</span><br><span class="line">    <span class="keyword">for</span>(i=len;i&gt;<span class="number">1</span>;i--)&#123;</span><br><span class="line">        Swap(A[i], A[<span class="number">1</span>]);</span><br><span class="line">        AdjustDown(A, i<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>堆支持删除和插入操作。删除堆顶元素时先将堆顶元素与最后一个元素互换，之后进行向下调整。插入元素时，直接将元素插入到最后的位置，之后进行向上调整。下面是执行向上调整的函数：<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">AdjustUp</span><span class="params">(ElemType A[], <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line"><span class="comment">//参数k为向上调整的结点，也就是堆中的元素个数</span></span><br><span class="line">    A[<span class="number">0</span>] = A[k];</span><br><span class="line">    <span class="keyword">int</span> i = k / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">0</span>&amp;&amp;A[i]&lt;A[<span class="number">0</span>])&#123;</span><br><span class="line">        A[k] = A[i];</span><br><span class="line">        k = i;</span><br><span class="line">        i = k/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    A[k] = A[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2>简单选择排序</h2><p>假设排序表为L[1...n]，第i趟排序即从L[1...n]中选择关键字最小的元素与L[i]进行交换，每一趟排序都可以确定一个元素的最终位置，经过n-1趟排序就可以使整个排序表有序。<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SelectSort</span><span class="params">(ElemType A[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n<span class="number">-1</span>;i++)&#123;</span><br><span class="line">        min = i;</span><br><span class="line">        <span class="keyword">for</span>(j=i+<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(A[j] &lt; A[min])</span><br><span class="line">                min = j;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(min!=i)</span><br><span class="line">            Swap(A[i], A[min]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;算法种类&lt;/th&gt;
&lt;th&gt;最好情况&lt;/th&gt;
&lt;th&gt;平均情况&lt;/th&gt;
&lt;th&gt;最坏情况&lt;/th&gt;
&lt;th&gt;空间复杂度&lt;/th&gt;
&lt;th&gt;是否稳定&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;直接
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>邹博机器学习课程第一讲：机器学习与数学基础笔记整理</title>
    <link href="http://Buevara.github.io/2017/07/03/%E9%82%B9%E5%8D%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%AC%E4%B8%80%E8%AE%B2%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/"/>
    <id>http://Buevara.github.io/2017/07/03/邹博机器学习课程第一讲：机器学习与数学基础笔记整理/</id>
    <published>2017-07-03T06:25:13.000Z</published>
    <updated>2018-04-06T05:03:57.294Z</updated>
    
    <content type="html"><![CDATA[<p>##机器学习###什么是机器学习？</p><blockquote><p>对于某给定的任务T，在合理的性能度量方案P的前提下，某计算机程序可以自主学习任务T的经验E；随着提供合适、优质、大量的静安E，改程序对于任务T的性能逐步提交。</p></blockquote><p>###这个任务最重要的是机器学习的对象：</p><blockquote><p>任务Task，T，一个或者多个经验Experience，E性能Performance，P</p></blockquote><p>总结来说：就是随着任务的不断执行，经验的累计会带来计算性能的提升。</p><p>###机器学习的一般流程</p><blockquote><ol><li><em>数据收集</em></li><li><em>数据清洗</em></li><li><em>特征工程</em></li><li><em>数据建模</em></li></ol></blockquote><p>注意：</p><ol><li>数据直接影响学习的结果。</li><li>对特征的选取不同，所得到的结果也会不同。</li><li>对于模型的选择，也有不同的方案，同样的数据用不同的模型所得到的结果不同。</li></ol><p>##机器学习的数学基础###高等数学</p><ul><li>导数</li></ul><blockquote><p>简单来说，导数是曲线的斜率，是曲线变化快慢的反应<strong>二阶导数</strong>是斜率变化快慢的反应，表征曲线<strong>凹凸性</strong>根据$\lim_{x\rightarrow \infty }(1+\frac{1}{x})^{x}=e$，可以得到函数$f(x)=lnx$的导数，进一步根据换底公式/反函数求导等，得到其他初等函数的导数。常用函数的导数${C}'=0$       ${({x}<sup>n)}'=nx</sup>{n-1}$${sinx}'=cosx$    ${cosx}'=-sinx$${(a<sup>{x})}'=a</sup>{x}lna$    ${(e<sup>x)}'=e</sup>x$${(log_{a}x)}'=\frac{1}{x}{log_{a}e}$ ${(lnx)}'=\frac{1}{x}$${(u+v)}'=u'+v'$ ${(uv)}'=u'v+uv'$</p></blockquote><p>例子：已知$f(x)=x^x,x&gt;0$，求解其最小值</p><blockquote><p>$t=x^x$$lnt=xlnx$两边对x求导:$\frac{1}{t}t'=lnx+1$令$t'=0$:$lnx+1=0$$x=(e)^{-1}$$t=e^{-\frac{1}{e}}$</p></blockquote><p>例子：推导$N\rightarrow \infty \Rightarrow lnN!\rightarrow N(lnN-1)$</p><blockquote><p>$lnN!=\sum_{i=1}^{N}lni\approx \int_{1}^{N}lnxdx$$=xlnx|<em>{1}<sup>{N}-\int_{1}</sup>{N}xdxlnx$$=NlnN-\int</em>{1}^{N}x\cdot \frac{1}{x}dx$$=NlnN-x|_{1}^{N}$$=NlnN-N+1$$\rightarrow NlnN-N$</p></blockquote><ul><li>Tayor公式</li></ul><blockquote><p>$f(x)=f(x_{0})+f'(x_{0})(x-x_{0})+\frac{f''(x_{0})}{2!}(x-x_{0})+...+\frac{f<sup>{(n)}(x_{0})}{n!}(x-x_{0})</sup>{n}+R_{n}(x)$令x=0，得到：$f(x)=f(0)+f'(0)x+\frac{f''(0)}{2!}x<sup>{2}+...+\frac{f</sup>{n}(0)}{n!}x<sup>{n}+o(x</sup>{n})$</p></blockquote><p>Taylor公式的应用：数值计算：初等函数值计算（在原点上展开）</p><blockquote><p>$sinx=x-\frac{x<sup>{3}}{3!}+\frac{x</sup>{5}}{5!}-\frac{x<sup>{7}}{7!}+\frac{x</sup>{9}}{9!}+...+(-1)<sup>{m-1}\frac{x</sup>{2m-1}}{(2m-1)!}+R_{2m}$$e<sup>{x}=1+x+\frac{x</sup>{2}}{2!}+\frac{x<sup>{3}}{3!}+\frac{x</sup>{4}}{4!}+...+\frac{x^{n}}{n!}+R_{n}$</p></blockquote><p>在实践中，往往需要做一定程度上的变换。</p><p>例子：计算$e^{x}$</p><blockquote><p>$x=k\cdot ln2+r$,$\left | r \right |\leqslant 0.5\cdot ln2$$e<sup>{x}=e</sup>{k\cdot ln2+r}$  $=e^{k\cdot ln2}\cdot e^{r}$  $=2^{k}\cdot e^{r}$</p></blockquote><ul><li>方向导数</li></ul><blockquote><p>如果函数$z=f(x,y)$在点$P(x,y)$是可微分的，那么，函数在该点沿任意方向$L$的方向导数都存在，且有：$\frac{\partial f}{\partial l}=\frac{\partial f}{\partial x}cos\varphi +\frac{\partial f}{\partial y}sin\varphi $其中，$\varphi$为x轴到方向L的转角。</p></blockquote><ul><li>梯度</li></ul><blockquote><p>设函数$z=f(x,y)$在平面区域D内具有一阶连续偏导数，则对于每一个点$P(x,y)\in D$,向量$$(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y})$$为函数$z=f(x,y)$在点$P(x,y)$的梯度，记作$gradf(x)$梯度的方向是函数在该点变化最快的方向</p></blockquote><p>###概率论</p><blockquote><ul><li>概率表达式：$P(x)\in [0,1]$若x为离散，则$P(x=x_{0})$表示$x_{0}$发生的<em>概率</em>若x为连续变量，则$P(x=x_{0})$表示$x_{0}$发生的<em>概率密度</em></li><li>累计分布函数：$\Phi (x)=P(x\leq x_{0})$$\Phi (x)$一定为<em>单调递增函数</em>。$min(\Phi (x))=0$,$max(\Phi (x))=1$</li></ul></blockquote><p>思考：将值域为[0,1]的单增函数$y=F(x)$看成<strong>X事件的累积概率函数</strong>，若$y=F(x)$可导，则$f(x)=F'(x)$为概率密度函数</p><blockquote><ul><li>概率公式条件概率：$P(A|B)=\frac{P(AB)}{P(B)}$全概率公式：$P(A)=\sum_{i}P(A|B_{i})P(B_{i})$贝叶斯(Bayes)公式：$P(B_{i}|A)=\frac{P(A|B_{i})P(B_{i})}{\sum_{j}P(A|B_{i})P(B_{j})}$</li></ul></blockquote><blockquote><ul><li>贝叶斯公式：<img src="http://osibywvsl.bkt.clouddn.com/bayes%E5%85%AC%E5%BC%8F.png" alt=""></li></ul></blockquote><blockquote><ul><li>分布<img src="http://osibywvsl.bkt.clouddn.com/%E5%90%84%E7%A7%8D%E5%88%86%E5%B8%83.png" alt=""></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##机器学习
###什么是机器学习？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于某给定的任务T，在合理的性能度量方案P的前提下，某计算机程序可以自主学习任务T的经验E；随着提供合适、优质、大量的静安E，改程序对于任务T的性能逐步提交。&lt;/p&gt;
&lt;/blockquote&gt;

      
    
    </summary>
    
    
  </entry>
  
</feed>
